{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "import importlib\n",
    "import relevancer as rlv\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from bson.objectid import ObjectId\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\",200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'relevancer' from '/Users/alihurriyetoglu/Dropbox/Projects/Relevancer/relevancer.py'>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(rlv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_token_pattern=r\"[#@]?\\w+\\b|[\\U00010000-\\U0010ffff]\"\n",
    "collection = 'all_data'\n",
    "rlvdb, rlvcl = rlv.connect_mongodb(configfile='myalldata.ini',coll_name=collection)\n",
    "# set active columns\n",
    "active_col = \"active_text\"\n",
    "rlv.set_active_column(active_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets: 48524\n"
     ]
    }
   ],
   "source": [
    "#importlib.reload(rlv)\n",
    "begin = ObjectId('55950fb4d04475ee9867f3a4')\n",
    "end = ObjectId('55950fc9d04475ee986841c3')\n",
    "\n",
    "# after the first iteration, the annotated clusters should be excluded from the clustering.\n",
    "# read this file from the tagged collection.\n",
    "annotated_tw_ids = ['563657483395530753', '563662532326330370', '563654330041909248', '563654944927281152', '563657924233289728', '563661021559390208', '563651950386757632', '563657164317667328', '563660271810383872', '563662538949160960'] #You should get the actual annotated tweet ids from the annotated tweets collection.\n",
    "#annotated_tw_ids = []\n",
    "# mongo_query=({'_id': {'$gte': begin, '$lte': end},'lang':'en'})\n",
    "tweetlist = rlv.read_json_tweet_fields_database(rlvcl, mongo_query=({'lang':'en'}), tweet_count=50000, annotated_ids=annotated_tw_ids)#=tweetsDF)\n",
    "\n",
    "rlv.logging.info(\"Number of tweets:\" + str(len(tweetlist)))\n",
    "print(\"Number of tweets:\",len(tweetlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-297-96aecd2165bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#annotated_tw_ids = []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# mongo_query=({'_id': {'$gte': begin, '$lte': end},'lang':'en'})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mrlv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json_tweet_fields_database\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrlvcl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmongo_query\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'lang'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_fields\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfields_to_read\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotated_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mannotated_tw_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#=tweetsDF)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/alihurriyetoglu/Dropbox/Projects/Relevancer/relevancer.py\u001b[0m in \u001b[0;36mread_json_tweet_fields_database\u001b[0;34m(rlvcl, mongo_query, read_fields, tweet_count, annotated_ids, annotated_users)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0mftwits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrlvcl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmongo_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtweet_count\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id_str'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mannotated_ids\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"user\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"screen_name\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mannotated_users\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# restrict line numbers for test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m                         \u001b[0;31m# break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alihurriyetoglu/anaconda3/lib/python3.4/site-packages/pymongo/cursor.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m         \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__collection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_refresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1077\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__manipulate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                 return db._fix_outgoing(self.__data.popleft(),\n",
      "\u001b[0;32m/Users/alihurriyetoglu/anaconda3/lib/python3.4/site-packages/pymongo/cursor.py\u001b[0m in \u001b[0;36m_refresh\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                 self.__send_message(\n\u001b[1;32m   1036\u001b[0m                     message.get_more(self.__collection.full_name,\n\u001b[0;32m-> 1037\u001b[0;31m                                      limit, self.__id))\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Cursor id is zero nothing else to return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alihurriyetoglu/anaconda3/lib/python3.4/site-packages/pymongo/cursor.py\u001b[0m in \u001b[0;36m__send_message\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_message_with_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__connection_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__exhaust\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alihurriyetoglu/anaconda3/lib/python3.4/site-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36m_send_message_with_response\u001b[0;34m(self, message, _must_use_master, **kwargs)\u001b[0m\n\u001b[1;32m   1203\u001b[0m                 \u001b[0msock_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"network_timeout\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1205\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__send_and_receive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msock_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alihurriyetoglu/anaconda3/lib/python3.4/site-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36m__send_and_receive\u001b[0;34m(self, message, sock_info)\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[0msock_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msendall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__receive_message_on_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msock_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0msock_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alihurriyetoglu/anaconda3/lib/python3.4/site-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36m__receive_message_on_socket\u001b[0;34m(self, operation, rqst_id, sock_info)\u001b[0m\n\u001b[1;32m   1172\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0moperation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__receive_data_on_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msock_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__send_and_receive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msock_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alihurriyetoglu/anaconda3/lib/python3.4/site-packages/pymongo/mongo_client.py\u001b[0m in \u001b[0;36m__receive_data_on_socket\u001b[0;34m(self, length, sock_info)\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEMPTY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1153\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msock_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEMPTY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mConnectionFailure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"connection closed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "importlib.reload(rlv)\n",
    "begin = ObjectId('55950fb4d04475ee9867f3a4')\n",
    "end = ObjectId('55950fc9d04475ee986841c3')\n",
    "\n",
    "# after the first iteration, the annotated clusters should be excluded from the clustering.\n",
    "# read this file from the tagged collection.\n",
    "annotated_tw_ids = ['563657483395530753', '563662532326330370', '563654330041909248', '563654944927281152', '563657924233289728', '563661021559390208', '563651950386757632', '563657164317667328', '563660271810383872', '563662538949160960'] #You should get the actual annotated tweet ids from the annotated tweets collection.\n",
    "fields_to_read = {'tweet_topic':1,'text': 1, 'id_str': 1, '_id': 0, 'user': 1}\n",
    "#annotated_tw_ids = []\n",
    "# mongo_query=({'_id': {'$gte': begin, '$lte': end},'lang':'en'})\n",
    "rlv.read_json_tweet_fields_database(rlvcl, mongo_query=({'lang':'en'}), read_fields=fields_to_read, tweet_count=50000, annotated_ids=annotated_tw_ids)#=tweetsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48524\n"
     ]
    }
   ],
   "source": [
    "tweetsDF = rlv.create_dataframe(tweetlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Be careful do not overwrite tweetsDFBackUP with a modified tweetsDF\n",
    "#tweetsDFBackUP = tweetsDF.copy()\n",
    "#len(tweetsDFBackUP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48524"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a clean copy \n",
    "importlib.reload(rlv)\n",
    "tweetsDF = tweetsDFBackUP.copy()\n",
    "len(tweetsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available attributes of the tweets: Index(['id_str', 'is_retweet', 'screen_name', 'text', 'active_text',\n",
      "       'texttok'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 48524 entries, 0 to 48523\n",
      "Data columns (total 6 columns):\n",
      "id_str         48524 non-null object\n",
      "is_retweet     48524 non-null bool\n",
      "screen_name    48524 non-null object\n",
      "text           48524 non-null object\n",
      "active_text    48524 non-null object\n",
      "texttok        48524 non-null object\n",
      "dtypes: bool(1), object(5)\n",
      "memory usage: 2.3+ MB\n",
      "\n",
      "tweet set summary: None\n",
      "0    1st Test, DAY 2 - TEA:\\n#IND 304/6 (91 ov, lead by 121, 1st inns)\\nH Singh 0*,\\nW Saha 25*,\\n#SL 183.\\n#CricbuzzCup\\n#SLvIND\n",
      "1       Younis Khan's 100th Test | Pakistan's go-to man gets to a landmark | Photo Gallery | ESPN Cricinfo http://t.co/ktnthao4hg\n",
      "2                                            Test Engineer &amp;#x2013; DV Cleared #it #job, Manchester... http://t.co/wMQdnMfifS\n",
      "3                                                                                             Today is an FTP test kind of day...\n",
      "4                                                                      @TomParker I failed my driving theory test this morning :(\n",
      "Name: text, dtype: object\n",
      "\n",
      "tweets are NOT tokenized.\n",
      "Retweets were eliminated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alihurriyetoglu/Dropbox/Projects/Relevancer/relevancer.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  print(tweetsDF[tok_result_col][:5])\n"
     ]
    }
   ],
   "source": [
    "tweetsDF[active_col] = tweetsDF[\"text\"]\n",
    "tweetsDF = rlv.tok_results(tweetsDF, elimrt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32977"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweetsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32977,\n",
       " Index(['id_str', 'is_retweet', 'screen_name', 'text', 'active_text', 'texttok',\n",
       "        'is_notrt'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsDF = rlv.normalize_text(tweetsDF)\n",
    "len(tweetsDF), tweetsDF.columns\n",
    "#tweetsDF[[active_col]] #rlv.logging.info(\"This text overwritten by normalization\" + str(tstDF[active_col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importlib.reload(rlv)\n",
    "rlv.set_active_column(active_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2310 entries, 89 to 337\n",
      "Data columns (total 7 columns):\n",
      "id_str         2310 non-null object\n",
      "is_retweet     2310 non-null bool\n",
      "screen_name    2310 non-null object\n",
      "text           2310 non-null object\n",
      "active_text    2310 non-null object\n",
      "texttok        2310 non-null object\n",
      "is_notrt       2310 non-null bool\n",
      "dtypes: bool(2), object(5)\n",
      "memory usage: 112.8+ KB\n"
     ]
    }
   ],
   "source": [
    "run_tweet_count = 5000\n",
    "tweetsDF2 = rlv.get_and_eliminate_near_duplicate_tweets(tweetsDF[:run_tweet_count], similarity_threshold=0.20, debug=True, test_threshold=run_tweet_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2233 entries, 265 to 2095\n",
      "Data columns (total 7 columns):\n",
      "id_str         2233 non-null object\n",
      "is_retweet     2233 non-null bool\n",
      "screen_name    2233 non-null object\n",
      "text           2233 non-null object\n",
      "active_text    2233 non-null object\n",
      "texttok        2233 non-null object\n",
      "is_notrt       2233 non-null bool\n",
      "dtypes: bool(2), object(5)\n",
      "memory usage: 109.0+ KB\n"
     ]
    }
   ],
   "source": [
    "tweetsDF3 = rlv.get_and_eliminate_near_duplicate_tweets(tweetsDF2, similarity_threshold=0.20, debug=True, test_threshold=run_tweet_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14878 entries, 140 to 36354\n",
      "Data columns (total 7 columns):\n",
      "id_str         14878 non-null object\n",
      "is_retweet     14878 non-null bool\n",
      "screen_name    14878 non-null object\n",
      "text           14878 non-null object\n",
      "active_text    14878 non-null object\n",
      "texttok        14878 non-null object\n",
      "is_notrt       14878 non-null bool\n",
      "dtypes: bool(2), object(5)\n",
      "memory usage: 726.5+ KB\n"
     ]
    }
   ],
   "source": [
    "tweetsDFx = rlv.get_and_eliminate_near_duplicate_tweets(tweetsDF, similarity_threshold=0.20, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is not any group of near-duplicate tweets.\n"
     ]
    }
   ],
   "source": [
    "tweetsDFx = rlv.get_and_eliminate_near_duplicate_tweets(tweetsDFx, similarity_threshold=0.20, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length at start: 14279\n",
      "There is not any group of near-duplicate tweets.\n"
     ]
    }
   ],
   "source": [
    "print(\"length at start:\",len(tweetsDFx))\n",
    "tweetsDFxx = rlv.get_and_eliminate_near_duplicate_tweets(tweetsDFx, similarity_threshold=0.20, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id_str', 'is_retweet', 'screen_name', 'text', 'active_text', 'texttok',\n",
       "       'is_notrt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsDFxx.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importlib.reload(rlv)\n",
    "rlv.set_active_column(active_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cluster_list = rlv.create_clusters(tweetsDFxx, my_token_pattern, nameprefix='1-', min_clusters=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 6\n",
      "available cluster information: dict_keys(['cno', 'user_entropy', 'cnoprefix', 'ctweettuplelist', 'rif', 'cstr', 'twids'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of clusters:\",len(cluster_list))\n",
    "print(\"available cluster information:\", cluster_list[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No: 64\n",
      "CStr: cluster number and size are: 64    67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"No:\",cluster_list[i]['cno'])\n",
    "print(\"CStr:\",cluster_list[i]['cstr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Tuple List:\n",
      "(0.65718208865539485, 'hearthstone â€“ test your knowledge with hearthstone quiz!\\xa0#3 urlurlurl urlurlurl')\n",
      "(0.686061211240381, 'test your knowledge &amp; answer the query ? urlurlurl')\n",
      "(0.69910990092702874, 'test your knowledge this #fridayafternoon with our #quiz urlurlurl #fridaychallenge')\n",
      "(0.70378298885456481, 'rtuusc: test your #climatechange knowledge: urlurlurl commit to #climate justice by joining commit2â€¦ urlurlurl')\n",
      "(0.71391582833475586, 'internal audit - quiz to test your knowledge ! - urlurlurl urlurlurl')\n",
      "(0.75375269906638098, 'test your knowledge of money with this \"roth ira quiz\" via @kiplinger urlurlurl #millennials #money')\n",
      "(0.75777105167092662, \"#fanoty - test your knowledge on history of premier league 'wonderkids' urlurlurl urlurlurl\")\n",
      "(0.76067765725186931, \"quiz: test your news knowledge: test your knowledge of this week's news and current events. urlurlurl\")\n",
      "(0.7740038578358005, 'test your @goosebumpsmovie knowledge with this quiz and earn entries! #goosebumpscontest - urlurlurl urlurlurl')\n",
      "(0.77808224011192095, 'test your workplace fire bulwark knowledge xkra')\n",
      "(0.7866588392868632, '@cherrychriss time to test your knowledge! follow @vanishind #iphone6 and play #stainsvanishmemoriesremain contest')\n",
      "(0.79049170299102511, 'quiz: test your news knowledge urlurlurl')\n",
      "(0.7910334987287857, 'test your knowledge of the gop presidential candidates.. related articles: urlurlurl')\n",
      "(0.79267569882660582, 'agency or porn? test your knowledge of company names &amp; adult movie titles urlurlurl #marketing #advertising')\n",
      "(0.7930696596252117, 'test your knowledge here @clubmahindra by answering ques and come up with your participation #historicindianmoments !!')\n",
      "(0.79964688490080471, 'test your knowledge of all things @pearljam with these 10 facts: urlurlurl urlurlurl')\n",
      "(0.80035133809294257, '@cool_vand time to test your knowledge on #historicindianmoments by answering simple questions \\n @clubmahindra')\n",
      "(0.80322010550636325, '#spanishsupercup quiz: test your knowledge ahead of the game  #supercopa #athleticfcb urlurlurl urlurlurl')\n",
      "(0.80455356589661831, 'are you a news buff? test your knowledge in the north wales quiz of the week urlurlurl urlurlurl')\n",
      "(0.80909668216668051, '@flatturtle @boskabout test your big data knowledge urlurlurl')\n",
      "(0.81104290117438083, 'the learning network: student crossword | tales of mystery and suspense: test your knowledge of tales of myste... urlurlurl')\n",
      "(0.81349775669720947, '@aryansarath time to test your knowledge skills with @clubmahindra answer questions with #historicindianmoments')\n",
      "(0.81396232458404127, '#identifythefighter: test your knowledge &amp; name this brave leader now! urlurlurl')\n",
      "(0.81711056928337533, '@clubmahindra do take part in the #historicindianmoments activity and test your knowledge on indian freedom fighters.')\n",
      "(0.81757168514562961, '@clubmahindra the #historicindianmoments activity talks about our freedom fighters. test your knowledge on the same.')\n",
      "(0.82939223983939614, 'episode 03 of the #hearthstone quiz is out! test your knowledge here: urlurlurl warning: answers may explode!')\n",
      "(0.83120484760705027, \"can you answer typical questions from your kids' standardized tests? take our quiz and test your knowledge. urlurlurl\")\n",
      "(0.83245847050536448, \"test your #cro knowledge with @whichtestwon &amp; @clicktale's conversion pop quiz.. urlurlurl\")\n",
      "(0.83627506375661409, '@garywelch1 have you been following the health news this week?test your knowledge with our weekly #healthcheck quiz urlurlurl')\n",
      "(0.8367851597368956, 'cycling quiz: 12 questions on bicycle tech through the ages: test your knowledge of some of the innov... urlurlurl #cycling')\n",
      "(0.83794943125482424, 'test your exide inverter battery knowledge with our #exidequiz urlurlurl')\n",
      "(0.83902093523974286, '@clubmahindra the #historicindianmoments activity talks about the indian freedom fighters. test your knowledge today.')\n",
      "(0.83917747953577027, 'test your knowledge of swansea city players past and present on ios urlurlurl #swansea')\n",
      "(0.84335045110165541, '@clubmahindra think you know about the indian freedom fighters? test your knowledge with the #historicindianmoments quiz.')\n",
      "(0.84687752244489278, 'do you know the right way to trim a hedge? test your knowledge with our infographic. urlurlurl urlurlurl')\n",
      "(0.84898643107135685, 'take the challenge! @cellcellpress launched challenges which test your knowledge and direct you to exciting research: urlurlurl')\n",
      "(0.85137230939331132, 'think you know #amsterdam? think again! test your knowledge with our #quiz! click here: urlurlurl urlurlurl')\n",
      "(0.85309639275560045, 'what leads to an increase in cerebral oxygen saturation? test your knowledge at urlurlurl and discuss it on the #forum')\n",
      "(0.85738011827184579, 'want to improve your english? test your knowledge on relative pronouns in our latest!\\nurlurlurl\\n#english #relativepronouns #etl')\n",
      "(0.85759747981371193, 'can you guess what it is? test your knowledge and tweet us your answers! #quiz #garden #horticulture #plants urlurlurl')\n",
      "(0.85875758024586379, \"think you know what's happening in the world? test your knowledge with this quiz developed at mit! urlurlurl\")\n",
      "(0.86067643901689639, \"last section of the #independenceday quiz! test your knowledge of sun's energy in west india. reply in comments urlurlurl\")\n",
      "(0.86380083515430151, 'i just took part in the rwc trivia quiz and scored 100% correct. test your knowledge against me! #rwc2015')\n",
      "(0.86454593147253123, 'in loving memory: how well do you know robin williams? test your knowledge urlurlurl')\n",
      "(0.86632578326558662, 'approvedaw: rt jiochat: it is on! the quiz starts in just 30 min, test your knowledge on freedom fighters and win â€¦ urlurlurl')\n",
      "(0.87288123437455689, '@physicianspract test your medical claims knowledge: take a quiz on cpt codes, denials, carcs, and other medic... urlurlurl')\n",
      "(0.87311500252867413, 'test your trivia knowledge. is the national anthem in the public domain? urlurlurl')\n",
      "(0.87590367876411135, 'test your knowledge ahead of the first leg between athletic club and fc barcelonaspanish super cup quiz  urlurlurl')\n",
      "(0.87639501421096366, \"@aki_anyway okay but i'm mainstream and hipster so lemme test your cartoon knowledge. teenage mutant ninja turtles 0_0\")\n",
      "(0.87751024161690405, 'check out @windhoekbeer_sa #purepubquizz. test your beer knowledge #getschooled #loveyourbeer')\n",
      "(0.87890392936303208, 'test your #nonleague knowledge now - join our #fantasy #football #competition to win a whopping Â£5k: urlurlurl')\n",
      "(0.88131213369702111, \"think you're a bit of a football anorak? test your knowledge of the game with our daily quiz: urlurlurl urlurlurl\")\n",
      "(0.88476418627677655, 'can you pass a high school reading test? test your knowledge of these assigned books. urlurlurl')\n",
      "(0.88814628669426421, 'i got pitmaster! test your bbq knowledge with the tums pitmaster challenge and enter to win! #tumsbbqpit urlurlurl')\n",
      "(0.89282860766940841, 'can you name the language that the word: \"kikusikitishacho\" belongs to? test your knowledge and see! urlurlurl via @guardian')\n",
      "(0.89415871496400878, \"come out tonight and test your #trivia knowledge with chad at @shmaltzbrewing &amp; pair your #beer with sweet mama's! urlurlurl\")\n",
      "(0.89428012973757265, 'urlurlurl\\ncome in and test your knowledge!  pbr progression at 7:00!\\n$3.00 three olives and $2.50 bandito shots!')\n",
      "(0.89709385484712512, 'millionaire quiz. test your general knowledge and show what you got! now on your ios device! urlurlurl urlurlurl')\n",
      "(0.89860910094489055, '#welcomedoc\\n\\nput your knowledge in physiology to test. stay tuned to answer simple trivia! urlurlurl')\n",
      "(0.9063594593998483, 'lots of everyday products come from plants. do you know which ones? test your knowledge @_marketsci @midtownfarmmkt this sat 8am-1pm!')\n",
      "(0.90700216499788999, 'new @chartmogul: the ultimate saas company tagline quiz. test your #saas company knowledge! urlurlurl urlurlurl')\n",
      "(0.92178884484922285, 'this evening why not test your knowledge against our quiz? there are prizes to be won and its free to enter! starts at 9.30pm')\n",
      "(0.92793850279305856, '#cfc chelsea fans! - come and take this test of your knowledge! urlurlurl #fb')\n",
      "(0.94217131935590348, \"test your bible knowledge! what did paul call the christian's human body?\\n#lifelight w/ tonyg on life 97.5 fm\")\n",
      "(0.95733956685124144, 'knowledge engineers are technical linguists that design, build, and test the knowledge of our nli solutions. learn mâ€¦urlurlurl')\n",
      "(0.961088850106807, 'test your bible knowledge!  in which book is it written \"can the ethiopian change his skin, or the leopard his spots?\"')\n",
      "(0.96522140252310462, 'i scored 59%! test _your_ world news knowledge with this quiz developed at mit! urlurlurl #worldnewsquiz')\n"
     ]
    }
   ],
   "source": [
    "print(\"Cluster Tuple List:\")\n",
    "print(*[(c[0],c[2]) for c in cluster_list[i]['ctweettuplelist']], sep='\\n')\n",
    "# Add any field you want to observe.\n",
    "i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reverse Frequency of the terms:\n",
      "1\n",
      "('24', ['you', 'urlurlurl'])\n",
      "('40', ['to'])\n",
      "('2', ['those', 'took', 'tried', 'doing that', 'in a', 'to get', 'for a', 'who didn', 'need to', 'asking', 'i took', 'true test', '1', 'stop mark', 'test done', 'not doing', 've seen', 'chaffinch', 'in my', 'm still', 'listen', 'destiny', 'week', 'like me', 'time', 'appalling weather', 'i got', 'opened', 'during the', 'lie', 'weather didn', 't think', 'birthday', 'that you', 'damn', 'd', 'as i', 'drive', '@youtube', 'again', 'hope', 'it feels', 'mark', 'you wanted', 'name', 'i have', 'for your', 'test in', 'i feel', 'different', 'to my', 'appalling', 'passed the', 'body', 'were', 'it didn', 'sitting', 'get one', 'for the', 'doing', 'maybe', 'already', 'the end', 't stop', 'play', 'of your', 'weather', 'could have', 'for my', 'head', 'i ve', 'tell', 'took my', 'software', 've', 'goddamn', 'to go', 'driving test', 'thank u', 'then', 'want', 't need', 'to study', 'hear', 'mark passing', 'my driving', 'stop', 's a', 'and it', 'high', 'still', 't take', 'say i', 'years', 't say', 'test you', 'i just', 'the night', 'test on', 'feel like', 'get to', 'urlurlurl appalling', 'to play', 'are you', 'i opened', 'shit', 'of the', 'feels', 'enough', 'think i', 'been', 'sure', 'ask', 'or', 'who', 'that didn', 'a @youtube', 'to be', 'know that', 't listen', 'hope i', 'much i', 'everyone', 'job', 'nope', 'test so', 'i could', 'his test', 'happy', 'good', 'i can', 'thank', 'man', 'run', 'that test', 'they didn', 'night', 'during', 'that the', 'have to', 'got a', 'urlurlurl urlurlurl', 'person', 'next', 'credit', 'french', 'just a', 'ace', 'try', 'my results', 'failed', 'said i', 'down', 'if they', 'test to', 'if you', 'it that', 'lord', 'i now', 'test didn', 'do it', 'least'])\n",
      "('7', ['this', 'on', 'was', 't study', 't even', 'an', 'are', 'a test', 'up', 't know', 'amp', 'even', 'one'])\n",
      "('1', ['the body', '2pm test', 'chill you', 'i did', 'in ep', 'pass me', 'up for', 'as you', 'only in', 'so amazing', 'faculty', 'ago', 'test woo', 'charge as', 'we didn', 'go see', 'realizing a', 'practice for', 'they would', 'year such', 'well i', 'ones and', 'soon', '@catrambo', 'a body', 'around', 'player', 'can enjoy', 'player s', 'my children', '@adamcodling', 'silly', 'technically', 'have been', 'they fell', 'get whitewashed', 'sounds awesome', 'the drivers', 'hard work', 'rankings', 'ep', 'marvan', 'destiny put', '13 and', 'speaking test', 'omg you', 'you are', 'flew', 'spot this', 'did alright', 'others', 'was r8', 'an invite', 'test random', 'sucked i', '@charlsbrooks failed', 'make', 'camera', 'bitch', '5', 'like a', '@patricklear95', 'application', '@planttrio thank', 'test day', 'fact', 'test but', 'before the', 'stutters', 'i laughed', 'memory', 'self', 'camera if', 'ðŸ˜† urlurlurl', 'at all', 'go try', 'mainly', 'of hair', 'conducted a', 'ok though', 'sitting in', 'the singing', 'enough as', 'positive', 'both', 'man didn', 's performance', 'hurt like', 'fell for', 'look', 'friday', 'scam', 'pass my', 'wondering', 'fact that', 'liked a', 'while', '@youtube video', 'ur', 'motorways', 'thats', 'a car', 'serious', 'ðŸ˜Ž', 'soon i', 'centre staff', 'coz u', 'another blood', 'this dr', 'thing', 'wouldn', 're', '#alevelresults', 'hmm', 'they drug', 'what', 'laughed knowing', 'less', 'someone credit', 'the faculty', 'without anyone', 'starting', 'screwed', 'tweet neh', 'car', 'but now', 'weekend and', 'twats', 'entrance test', 'shave because', '5min', 'wanted because', 'but don', '@nklt07', 'panic', 'amp viel', 'concussion', 'country scouse', 'test driving', 'red like', 'explode', 'selvig', 'blind', 'telling me', 'bungie didn', 'james although', 'like my', 'thought this', 'provide', 'my marks', 'name was', 'the back', 'said so', 'of duty', 'put', 'attack', 'chase need', 'r from', 'snore', 'everyone how', 'detector', 'biggest run', 'm so', 'electric', 'do urlurlurl', 'ðŸ˜’', 'such', 'bike i', 'should have', 'seen bare', 'color', '#blindfaith urlurlurl', 'again better', 'morning', '#blindfaith', 'test cricket', 'w @nampaikid', 'well urlurlurl', 'm going', 'bitter that', 'determine', 'physical phonesets', 'once', 'numbing', 'the job', 'paper up', 'ðŸ˜†', 'want it', 'seat', 'okay', 'k', 'results day', 'for asking', 'test ilu', 'inclusive regex', 'r8', 'u either', 'application amp', 'test champs', '@bhogleharsha', 'playlist', 'i apologize', 'for something', '@moonovermarin_ didn', '@darmchaircritic @akscoop6', 'french that', 'regex', 'help you', 'cockney', 'hair', 'typing test', 'one who', 'ilu #blindfaith', 'boy error', 'something', 'doc said', '@nampaikid @arantzaoffi', 'duty by', 'accents', 'hearing', 'boy once', 'all confident', 'not to', 'scouse', 'test @ims', 'pt', 'just didn', 'steam goddamn', 'turn super', 'numbing cream', '2nd test', 'time ðŸ˜Ž', 'test exam', 'of one', 't manage', 'i liked', 'can t', 'motorways that', 'much credit', 'a job', 'ðŸ˜µ ðŸ˜³', 'remember in', '4am', 'others yet', 'just test', 'its original', 'the lab', 'teacher is', 'ðŸ˜“', 'day because', 'in one', 'tho', 's ok', 'questioning', 'binned', 'lol my', 'bc i', 'color blind', 'boy oh', 'told me', 'a video', 'physical', 'send me', 'the need', 'test hahaha', 'hoped', '2nd', 'get an', 'richard branson', 'near high', 'so he', 'do the', '@charlsbrooks', 't receive', 'the results', 'hoped for', 'sisters', 'ha a', 'laughably', 'was i', 'you prolly', 'test amp', 'i v', 'went', 'test it', 'out i', 'went around', 'u i', 'like i', 'thats my', 'damn sure', 'me nope', 'rly', 'that again', 'u didn', 'nothing like', 'the entrance', 'instructor telling', 'wrong', 'few', 't determine', 'faculty didn', 'wondering why', 'though', 'lets', 'ace the', 'test drive', 'software amp', 'for him', 'help', 'online', 'get that', 'were just', 'pinky', '@thinkgeek glad', 'again and', 'to rejoice', 'this lol', 'pheww i', 'something he', 'me to', 'nope person', 'alright better', 'know about', 'do your', 'work you', 'fucked up', 't ask', 'only to', 'my paper', 'tried by', 'be the', 'loved', 'iu', 'typing', 'pass out', 'like bitch', 'but audio', 'breathalizer typing', 'tv', 'test rankings', 'few minutes', 'super fast', 'for another', 'never', '@youtube playlist', 'lord sugar', 'atleast', 'where', 'like chill', 'wow', 'got croissants', 'ade', 'off if', 'have my', 'online application', 'too lol', 'audio is', 'remember that', 'amp i', 'see', 'november', 'have 2', 'about this', 'd be', 'got the', '@975mornings', 'not sure', 'much drama', 'coming', '@the_blueprint dudes', 'wow that', 'h i', 'going to', 't give', 'blind ishihara', 'better next', 'womens teams', 'giving', 'take the', 'but he', 'much of', 'conducted', '21st', 'ask for', 'why d', 'can test', 'answering math', 'and damn', 'one reacts', 'expensive', 'test this', 'last year', 'they hoped', 'tell us', 'yr 13', 'all @patricklear95', 'that happened', 'video stutters', '@planttrio', 'break', 'even bother', 'morning cause', 'tragic', 'idk how', '2 apneas', 'five', 'down while', '1978', 'years for', 'against lions', 'ooft didn', 'listen and', 'why they', 'i think', 'nocerino destiny', 'my 21st', 'relieved', 'ways to', 'ima', 'relate to', 't fail', 'monday ðŸ˜’', 'so many', 'reyna and', 'entrance', '@jonmarks975', 't hurt', 'many fancy', 'things not', 'relevant', 'absolute', 'blurred', 'how fucked', 'a shave', 'schizo test', 'married twice', '100 ways', 'married', 'fly anyway', 'goddamn thats', 'before and', 'silly because', 'even remember', 'lowest', 'test due', 'woo lets', 'high in', 'was relevant', 'had 2', 'dereliction', 'ripped my', 'of seen', 'biggest', 'benjamin', 'ha', 'fell', 'the one', 'is fine', 'ðŸ˜³', 'work not', 'enough to', 'clearly didn', 'playing', 'of country', 'ate pinky', 'country', 'the concussion', 'happened', 'relate', 'failed ur', 'want but', 'buy', 'password', '100', 'money on', 'scouse chaffinch', 'pinky amp', 'number is', 'lets go', '@itvthismorning', 't urlurlurl', 'added', 'give', 'body spray', 'just for', '@danny_logan', 'score near', 'like bungie', 'notice', 'car and', 'prepare for', 'pheww', 'aquino @withlovekrisaquino', '@tonelowks702 i', '@the_blueprint', 'technically but', 'ed', '#democracy', 'some', 'whitewashed', 'good enough', 'awesome', 'up u', 'instead that', 'result', '@charliewharton', 'red', 'test charge', '200 was', 'why are', 'just how', 'performance', 'just found', 'they had', 'answering', 'rankings didn', 'wink of', 'take vcinese', 'surplus of', 'french things', 'anyone asking', 'i made', 'w', 'top', 'and get', 'send', 'laughed', 'atleast not', 'could start', 'the wig', 'locked up', 'top heavy', '2 test', 'for passing', 'reading this', 'me with', 'screwed ðŸ˜£', 'fucking', 'songs from', 'what they', 'a 2pm', 'neh', 'prolly fly', 'accents in', 'determine a', 'i snore', 'how can', 'hack', 'neh that', 't but', 'panic attack', 'a piss', 'are acceptable', 'know 200', 'belt', '@royalmail you', 'i flew', 'need the', 'gotta have', 'claim', 'c', 'provide me', 'my assessment', '@purpdrank', '1 urlurlurl', 'week krypton', '@ims', 'cricket for', 'just came', 'to marvan', 'maybe i', 't literally', 'fail the', 'i wanted', 'oh boy', 'teams i', 'can relate', 'u are', 'school boy', 'a simple', 'pop', '@royalmail', 'ear', 'play games', 'ima do', 'min', 'of sleep', 'a hat', 'how one', 'rly happy', 'telling', 'due monday', 'for womens', 'cause urine', '@fwildecricket test', 'is true', 'you re', 'glad', 'passed but', 'for w', 'even go', 'listening test', 'fine urlurlurl', 'did get', 'branson', 'piss', 'fuck', 'negligence', 'as five', 'test phase', 'ur test', 'math test', 'test @itvthismorning', 'tv didn', 'sounds', 'while answering', 'marks', 'kris aquino', '#alevels', 'least it', 'just tried', 'tomorrow if', 'on @cbs4indy', 'staff didn', 'credit given', '2pm', 'like starting', 'bc', 'up in', 'albums i', 'expected as', '2 and', 'my blood', 'although that', 'start working', 'how i', 'ilu', 'error didn', '@cburgdorf', 'your driving', '@jmebbk', 'detector test', 'had passed', 'we were', '34 years', 'oh', 'amazing', 'i the', 'spray that', 'bitch don', 'min didn', 'bare i', 'this urlurlurl', 'my capture', 'now after', 'lie detector', 'define you', 'feels to', 's just', 'test reyna', 'should', 'a surplus', 'so don', 'sugar', '@adamcodling where', '@jonmarks975 @975mornings', 'negative hardly', 'than', 'gotta', 'twats how', 'that and', 't happen', 'my name', 'test well', 'arriving all', 'jack shit', 'been for', 'to those', 'aquino', 'twice both', 'is sick', 'hat of', 'well in', 'r', 'honesty i', 'prolly', 'dudes can', 'setlist', '16th birthday', 'loud got', 'did you', 'i d', 'cared', 'i remember', 'result you', 'learn this', 'krypton', 'croissants from', 'stay', 'the 2nd', 't define', 'character', 'notice i', 'highest or', '#pll but', 'bother to', 'same place', 't wake', 'a on', 'do a', 'self respect', 'me wonder', 's test', 'name is', 'us the', 'drug', 't score', 'h', 'tweetd', 'down if', 'silently hoping', 'factor intelligence', 'chaffinch cockney', '@catrambo if', 'songs', 'hey today', 'chance', '#fuming', 'expensive beta', 'let s', 'on my', 'nasa', 'sun can', 'but it', '2 years', 'or a', 'it i', 'ðŸ˜‚ @katieburke125', 'idk', 'ask lord', 'already married', 'simple schizo', 'time to', 'now look', 'due', 'deadline', 'by ear', 'try for', 'ways', 'air', 'only one', 'better at', 'things during', 'amp we', 'credit that', 'next urlurlurl', 'without', 'wealthy sport', 'claim they', 'call', 'money', 'original name', 'a dereliction', 'marvan ðŸ˜‚', 'for 34', 'and only', 'nocerino', 'things that', '@charliewharton u', 'so my', 'to tame', 'passed my', 'test like', 'a hearing', 'ðŸ˜£', 'last week', 'true true', 'is red', 'can they', 'my purse', 'cream wore', 'intelligence', 'opened a', 'then didn', 'came up', 'arriving', 'stay to', 'random', 'g', 'to ace', '4am for', 'it wrong', 'fun', 'enjoy destiny', 'that sounds', 'coz', 'done to', 'learn', 'steam', 'the dvsa', 'u finished', 'test me', 'because they', 'knowing', 'still wondering', 'the air', 'approach', 'bother', 'get crazy', 'to pass', 'hurt', 'the next', 'knowing i', '21st birthday', '#smartdoll frame', 'bitter', 'to help', 'true too', 'invite to', 'the #smartdoll', 'my h', 'error', 'more test', 'an expensive', 'he could', 'you drive', 'the speaking', 'destiny if', 'wrong benjamin', 'wore off', 'wink', 'working', 'but that', 'fail', '34', 'some of', 'know they', 'hear what', '#resultsday', 'math', 'branson they', '#directionersfuneral talking', 'sun', 'cream', 'birthday after', 'peeps discussing', 'thru the', 'england', 'given to', 'wouldn t', 'world champions', 'can provide', 'this morning', 'sleep need', 'be reading', 'make up', 'locked', 'job just', 'drivers ed', 'starting the', 'positive #alevels', 'high enough', 'someone', 'fly', 'hahaha i', '@akscoop6 the', 'hardly negligence', 'buy i', 'boy didn', 'better fucking', 's the', 'a chance', 'a serious', 'was negative', 'drug test', 'sick', 'spot', 'sick on', 'memory mainly', 'properly', 'knew you', 'simple', 'do after', 'shave', 'schizo', 'naughty boy', 'receive an', 'whole', '@katieburke125', 'highest', 'failed to', 'nope hahaha', 'my 3', 'cancelled', 'bombed the', '@cbs4indy', 'capable', 'naughty', 'wanted it', 'email', 'heavy but', 'prepare', 'weekend', 'electric motorways', 'vine by', 'try others', 'are it', 'apneas during', 'test why', 'character be', 'ðŸ˜“ idk', 'tame', 'turn', 'loved ones', '@danny_logan i', 'maybe maybe', 'it properly', 'one because', 'repair', 'now i', 'after u', 'v test', 'nasa didn', 'phase', 'drama', 'at 4am', 'snore loud', 'after my', 'nan', 'a thing', 'have different', 'and some', 'tragic much', 'so relieved', 'maths', 'splitter its', 'to urlurlurl', 'the machine', 'lab', 'have played', 'my password', 'video to', 'thanks', 'had of', 'although', 'yet cause', 'do anything', 'pop like', 'my numbing', 'dr', 'man locked', 'vs', 'all honesty', 'chill', 'yeah but', 'reading', 'the only', 'did it', 'enjoy', 'maths now', 'respect isn', 'do an', 'candy', 'maine s', 'tell everyone', 'cause i', 'selvig to', 'invite', '@sakun_sd', 'test prediction', 'ripped', 'which is', 'it and', 't ðŸ˜¶', 'serious test', 'test 1978', 'hard', 'the sun', 'how it', 'negligence urlurlurl', 'they claim', 'honesty', 'playing an', 'they want', 'expected', '#alevelresults don', 'i bombed', 'i should', 'parts of', 'a goddamn', 't fake', 'vcinese', 'its', 'sucked', '@lindseyleew yeah', 'done they', 'realizing', 'pak', 'just hope', 'minutes on', 'two test', 'told', 'iu conducted', 'when i', 'a shit', 'over did', 'crazy', 'manage to', 'like we', 'kill', '@o2 repair', 'an email', 'this last', 'fake', 't go', 'i know', 'monday', 'the teacher', 'drive amp', 'i never', 'your test', '@fwildecricket', 'ear and', 'ishihara', 'talking to', 'playlist urlurlurl', 'in #pll', 'played', 't you', 'ed test', 'in different', 'instead', 'feel down', 'exam last', '@nampaikid', 'machine', 'awesome didn', 'singing', 'wake', 'performance against', 'm not', 'the fun', '@nklt07 nope', 'both didn', 'champs binned', 't send', 'amp buy', 'to say', 'crazy james', 'the head', 'hmm i', 'school', 'reacts', 'you just', 'bare', 't spot', 'u can', 'different accents', 'they cancelled', 'five physical', 'teams', 'goddamn breathalizer', 'us playing', '@rjhbikeschool', 'ghostbusters lol', 'test when', 'viel told', 'to a', 'for coming', 'end pretty', 'year', 'our', 'thought', 'motivation to', 'prediction was', 'is silly', 'from @rjhbikeschool', 'wonder', 'which', 'up at', 't cover', 'anyway tho', 'scores don', 'urine', 'silently', 'mainly so', 'good lord', 'dna', 'm rly', 'cover', 'ðŸ˜¶', 'me an', 'dvsa are', 'tweet', '@dudbun got', 'listen 2', 'an a', 'need for', 't u', 'test before', '@withlovekrisaquino', 'for how', 'me like', 'tweetd those', 'back amp', 'in french', 'were test', 'wig', 'that urlurlurl', 'that bike', 'cause just', 't authorize', 'marks are', 'him #fuming', 'kill to', 'required deadline', 'i added', 'test @melaniexinnyee', 'finished', 'of candy', 'place', 'test ðŸ˜†', 'found', 'against', '@jmebbk @charliewharton', 'the whole', 'feel good', 'the result', 'loud', 'world', 't try', 'lay money', 'you gotta', 'given', 'sport', 'vine', 'audio', 's it', 'that if', '@cburgdorf just', 'assessment', 'listening', 'once tried', 'seat belt', 'night doc', 'a lie', 'number', 'if only', 'yet', '#womensashes', '3', '#democracy is', 'looked', 'factor', 'hardly', 'champions high', 'our nan', 'that in', 'one test', 'either way', 'driving a', 'fast', 'the highest', 'original', 'going', 'lot', '@kssksam @darmchaircritic', 'james', 'around a', '@grahamrahal @wheelsup', 'whitewashed urlurlurl', 'c my', '#smartdoll', 'ðŸ˜µ', 'put me', 'rejoice', 'that is', 'years ago', '@moonovermarin_', 'video from', '@akscoop6', 'was the', 'the same', 'amazing make', 'v', 'today ðŸ˜“', 'lab today', 'drivers', 'already wealthy', 'how ima', 'test cause', 'start', 'lol i', '@tonelowks702', 'dr didn', 'see how', 'anyway', 'know jack', 'run a', 'fine', 'made so', 'or lowest', 'confident for', 'test he', 'that pt', 'a min', 'your self', 'ep 1', 'a dna', 'give a', 'dereliction of', 'have thought', 'only had', 'isn', 'urine was', 'say call', 'a panic', 'benjamin franklin', 'driving theory', 'play urlurlurl', 'less like', 'though more', 'theory test', 'wait', 'test us', 'relevant world', 'more inclusive', '1978 style', 'then said', 'the laughably', 'ok', 'yeah', 'charge', 'clearly', 'today s', 'the songs', 'taking', 'pt test', 'wig like', 'kris', 'hoping that', 'tomorrow', 'a lot', 'practice', 'feel about', 'feels like', 'your number', 'and now', 'end of', 'rejoice if', 'everyone is', 'viel', 'the wanted', 'back', 'his driving', 'test again', 'driver', 'person but', '@rjhbikeschool urlurlurl', 'a #democracy', 't prepare', '@de180y', 'because tv', 'cover ðŸ˜µ', 'capable okay', 'authorize', 'verify he', 'franklin', 'krypton factor', 'just tell', 'beta test', 'are capable', 'confident', 'came', 'one wink', '@lindseyleew', 'are coz', 'today didn', '@uwasanoawasu maybe', 'womens', 'purse', 'fucked', 'have the', 'fast and', 'wore', 'a quick', 'run chase', 't approach', 'a turn', 'gonna', '13', 'glad i', 'breathalizer', 'stutters but', 'questioning things', 'from the', 'different parts', 'score', 'the required', 'a damn', '@dudbun', 't explode', 'nothing', 'scores', 'they were', 'by an', 'those who', 'happen in', 'amp naughty', 'the listening', 'better than', '@sakun_sd ade', 'place as', 'have us', 'you giving', 'all the', '@darmchaircritic', 'him', 'i cared', 'wanted remember', 'albums', 'vcinese test', 'lions', 'study at', 'test vs', 'u thank', 'this week', 'm already', 't ughhhh', 'cricket', 'gonna pass', 'jack', 'up to', 'thru', 'test sucked', 'results they', 'test scores', 'in all', 'love', 'sleep', 'style', '#pll', 'pretty well', 'deadline #fail', 'i work', 'like last', 'on sitting', 'games', 'intelligence test', 'paper', 'i clearly', 'asking about', 'wake up', 'receive', 'inclusive', 'knew', 'flew thru', 'if didn', 'to verify', 'sure how', 'pretty', 'lot of', 'on a', 'off', 'if the', 'it was', 'day with', 'thing ask', 'are absolute', 'hahaha at', 'ade you', 'piss test', 'opened it', 'tried that', 'absolute twats', 'you gonna', 'a more', 'thanks for', 'happen', 'test instead', 'seen 1', 'even stay', 'working tomorrow', 'and richard', 'still bitter', 'to k', '@grahamrahal', 'literally kill', 'where my', 'made', 'asking #resultsday', 'dvsa', 'on it', 'ahhh', 'exam test', 'discussing work', 'test let', 'respect', 'the maine', 'acceptable', 'not much', 's how', 'driving g', 'literally', 'from albums', 'on the', 'had a', '@arantzaoffi vine', 'parts', 'head splitter', 'a true', 'nan for', 'amp then', 'by @purpdrank', 's friday', 'happy bc', 'pass that', 'ooft', 'lay', 'lie to', 'quick', 'i hope', 'you notice', 'you practice', 'person omg', 'from our', '@de180y i', 'a few', 'taking an', '16th', 'study the', 'dudes', 'finished taking', 'you and', 'i knew', 'maine', 'much or', 'apologize to', 'ace two', 's why', 'exam results', 'define', 'day 2', '@thinkgeek', 'coming up', 'break down', 'super', 'cockney chaffinch', 'yr', 'peeps', 'do blood', 'how are', 'beta', 't c', 'looked like', 'cos', 'would have', 'setlist r', '@wheelsup', 't end', 'verify', 'lord i', 'results i', 'pass the', 'played technically', 'was blurred', 'g test', 'vs pak', 're just', '@kssksam', 'be positive', 'at least', 'even test', 'woo', 'and ace', 'dna test', 'fancy french', 'get my', 'when', 'wanted amp', 'm better', 'reyna', 'been true', 'hey', 'doc', 'results you', 'study and', 'you ha', 'lions before', 'm screwed', 'know this', 'he ripped', 'staff', 'my seat', 'why was', 'hear peeps', 'way', 'test soon', 'of it', 'amp video', 'england to', 'lowest #alevelresults', 'theory', 'phonesets to', 'capture software', 'at maths', '5min hack', 'hack didn', 'i expected', 'anyone', 'frame test', 'fucking get', 'happened in', 'acceptable ðŸ˜‚', 's character', 'this was', 'my loved', 'fun of', 'birthday @thinkgeek', 'the software', 'would of', 'chaffinch urlurlurl', 'let', '@o2', '3 sisters', '@arantzaoffi', 'many', 'added a', 'assessment test', 'same', 'alright', 'bombed', 's setlist', 'because you', 'last test', 'champions', 'my driver', 'have said', 'know chaffinches', 'candy in', 'ate', 'the hard', 'he had', 'than i', 'after yr', 'did to', 'was biggest', 'champs', 'two', 'donti you', '@975mornings i', 'reacts is', 'need more', 'look less', 'binned because', 'manage', 'frame', 'explode atleast', 'regex just', '#directionersfuneral', 'surplus', 'happy 16th', 'the camera', '@melaniexinnyee', 'sure not', 'love u', 'sisters ate', 'remember sitting', 'fag', 'the @o2', 'out', 'laughably top', 'teacher', 'you did', 't learn', 'near', 'prediction', 'ðŸ˜³ ðŸ˜±', 'november which', '200', 'apneas', 'to hear', 'driver s', 'ðŸ˜‚ fag', 'password donti', 'the exam', 'be in', 'never did', 't want', 'd i', 'another', 'test my', 'concussion test', 'would lay', 'work the', 'us all', 'think #womensashes', 'omg', 'wealthy', 'urlurlurl didn', 'ughhhh', 'duty', 'seen it', 'test thanks', 'attack ahhh', 'my head', 'body in', 'that would', 'me that', 'ðŸ˜±', 'one to', 'i love', 'test tell', 'i failed', 'scam test', 'children', 'over', '@withlovekrisaquino my', 'damn that', 'pass hear', 'one s', 'even do', 'done ðŸ˜‚', 'an already', 'of memory', 'you lie', 'is questioning', 'shit without', 'more motivation', 'sugar and', 'hoping', 'last november', 'call ghostbusters', 'fuck man', 'we went', 'instructor', 'tame the', '5 player', 'next time', '#fail', 'found 100', 'work that', 'talking', 'i tweetd', 'do better', 'twice', 'phonesets', 't work', 'up cos', 'minutes', 'an online', 'i looked', 'cos i', 'discussing', 'hat', 'such tragic', 'repair centre', 'pak didn', 'like to', 'of done', 'wonder if', 'chaffinches have', 't much', 'croissants', 'liked', 'today and', 'ghostbusters', 'test only', 't run', '@bhogleharsha @fwildecricket', 'isn t', 'spray', 'k pop', 'those 5', 'negative', 'bike', 'but how', 'drive electric', 'motivation', 'too', 'centre', 'either', 'ones', 'the day', 'approach me', '@wheelsup didn', 'belt on', '@purpdrank urlurlurl', 'ishihara test', 'on test', 'heavy', 'i would', 'only i', 'shit ðŸ˜‚', 'a color', 'sitting the', 'about my', 'your last', 'apologize', 'head didn', 'now you', '@uwasanoawasu', 'cancelled my', 'night before', 'donti', 'required', 'of just', 'even take', 'richard', 'bungie', 'my instructor', 'whole weekend', 'test today', 'speaking', 'i over', 'a scam', 'fancy', 'splitter', 'my tweet', 't break', 'authorize selvig', 'quick 5min', 'giving someone', 'a man', 'to me', 'chaffinches', 'an exam', 'wait a', 'up with', 'ago lol', 'and then', 'friday i', 'least i', 'chase', 'hearing test', 'anything', 'take a', 'capture'])\n",
      "('56', ['the'])\n",
      "('4', ['that i', 'to test', 'me i', 'study for', 'today', 'better', 'wanted', 'had', 'last', 'ðŸ˜‚', 'boy', 'true', 'got', 'at', 'to the', 'all', 'be', 'from', 'as', 't pass', 'passed', 'results', 'test i', '2', 'and didn', 'why', 'work', 'get the', 'well', 'it s'])\n",
      "('26', ['that', 'my'])\n",
      "('84', ['test'])\n",
      "('8', ['t get', 'u', 'you didn', 'know', 't have'])\n",
      "('3', ['said', 'done', 'we', 'with a', 'remember', 'test the', 'i passed', 'seen', 'blood test', 'he didn', 'day', 'blood', 'how much', 'my test', 'exam', 'think', 'would', 'after', 't do', 'test of', 'passing', 'go to', 'by', 'us', 'if i', 'passing his', 'is a', 'with', 'things', 'because i', 'his', 'hahaha', 'could', 'say', 'lol urlurlurl', 'before', 'more', 'video', 'end', 'cause', 'about', 'that s', 'but i', 'take', 't feel'])\n",
      "('13', ['s', 'get'])\n",
      "('5', ['only', 'your', 'lol', 'don t', 'driving', 'did', 'feel', 'need', 'now', 'in the', 'don', 'go'])\n",
      "('12', ['like'])\n",
      "('11', ['just', 'they', 'the test', 'me', 'do'])\n",
      "('9', ['is', 'study', 'm', 'i m', 'and i'])\n",
      "('15', ['in', 'of'])\n",
      "('39', ['i didn'])\n",
      "('101', ['i', 't'])\n",
      "('10', ['how', 'but', 'if'])\n",
      "('6', ['he', 'have a', 'to do', 'can', 'because', 'test and', 't test', 'so', 'not', 'pass', 'much'])\n",
      "('17', ['have', 'it'])\n",
      "('20', ['for'])\n",
      "('93', ['didn', 'didn t'])\n",
      "('23', ['and'])\n",
      "('42', ['a'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Reverse Frequency of the terms:\")\n",
    "print(i)\n",
    "print(*Counter(cluster_list[i-1]['rif']).most_common(), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters were written to the collection: coll123_clusters\n"
     ]
    }
   ],
   "source": [
    "collection_name = collection + '_clusters'\n",
    "rlvdb[collection_name].insert(cluster_list) #Each iteration results with a candidate cluster list. Each iteration will have its own list. Therefore they are not mixed.\n",
    "print(\"Clusters were written to the collection:\", collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweets_as_text_label_df:     label                                               text\n",
      "0   relif  RT @OliverMathenge: Meanwhile, Kenya has donat...\n",
      "1  social  Yow ehyowgiddii! Hahaha thanks sa flood! #inst...\n"
     ]
    }
   ],
   "source": [
    "tweets_as_text_label_df = pd.DataFrame({'label' : ['relif', 'social'] , 'text' : [\"RT @OliverMathenge: Meanwhile, Kenya has donated Sh91 million to Malawi flood victims, according to the Ministry of Foreign Affairs.\" , \"Yow ehyowgiddii! Hahaha thanks sa flood! #instalike http://t.co/mLaTESfunR\"]})\n",
    "print(\"tweets_as_text_label_df:\", tweets_as_text_label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In get_mnb_classifier:\n",
      "Pickle file was written to vectorizer_and_classifier_dict.pickle\n"
     ]
    }
   ],
   "source": [
    "# get vectorizer and classifier\n",
    "vect_and_classifier = rlv.get_vectorizer_and_mnb_classifier(tweets_as_text_label_df, my_token_pattern, pickle_file=\"vectorizer_and_classifier_dict\")\n",
    "vectorizer, mnb_classifier = vect_and_classifier[\"vectorizer\"], vect_and_classifier[\"classifier\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get label for a new tweet:\n",
    "ntw = vectorizer.transform([\"Why do you guys keep flooding TL with smear campaign for a candidate you dont like.You think you can actually influnece people's decision?\"])\n",
    "predictions = mnb_classifier.predict(ntw)\n",
    "print(\"Predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rlv.logging.info('\\nscript finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In get_tw_ids\n",
      "Length of the tweet ids and the first then ids 48524 ['631754887861112832', '631754877526372352', '631754882907811841', '631754880378609664', '631754869959979008', '631754870232485888', '631754886422638592', '631754869347475458', '631754865627148288', '631754864675000320']\n"
     ]
    }
   ],
   "source": [
    "tw_id_list = rlv.get_ids_from_tw_collection(rlvcl)\n",
    "print (\"Length of the tweet ids and the first then ids\",len(tw_id_list),tw_id_list[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
